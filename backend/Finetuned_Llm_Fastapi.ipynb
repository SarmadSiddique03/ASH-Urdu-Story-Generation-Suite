{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb425f39",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install unsloth \"xformers==0.0.28.post2\"\n",
    "# Also get the latest nightly Unsloth!\n",
    "!pip uninstall unsloth -y && pip install --upgrade --no-cache-dir \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59cb28b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install fastapi nest_asyncio uvicorn pyngrok diffusers transformers torch accelerate python-multipart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f3d070",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!ngrok config add-authtoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d4a21",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import os\n",
    "\n",
    "# ✅ Auto-detect best dtype\n",
    "dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "# ✅ Use 4-bit quantization if on GPU (reduces VRAM usage)\n",
    "load_in_4bit = torch.cuda.is_available()\n",
    "\n",
    "# ✅ Load the fine-tuned model and tokenizer\n",
    "model_name = \"sarmadsiddiqui29/Llama-3.1-8B-Instruct-Urdu-Story\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=model_name,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    token=os.getenv(\"HUGGINGFACE_TOKEN\"),\n",
    ")\n",
    "\n",
    "# ✅ Ensure model is on the correct device\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# ✅ Confirm everything is set correctly\n",
    "print(f\"Model loaded on {device} with dtype={dtype} (4-bit={load_in_4bit})\")\n",
    "FastLanguageModel.for_inference(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00392d2f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import re\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from unsloth import FastLanguageModel\n",
    "import uvicorn\n",
    "import os\n",
    "import nest_asyncio\n",
    "from pyngrok import ngrok\n",
    "import asyncio\n",
    "from threading import Thread # Import Thread\n",
    "\n",
    "# Apply nest_asyncio to allow running asyncio event loop in environments like notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# ----------------------------\n",
    "# Helper Functions\n",
    "# ----------------------------\n",
    "\n",
    "def fix_spacing(text):\n",
    "    \"\"\"Fix missing spaces in Urdu text.\"\"\"\n",
    "    # Using the updated regex for Urdu characters\n",
    "    return re.sub(r'(?<=[؀-ۿ])(?=[؀-ۿ])', ' ', text)\n",
    "\n",
    "def extract_text_after_last_story(text: str) -> str:\n",
    "    \"\"\"\n",
    "    Extracts text after the last occurrence of \"Story:\" and ensures it ends with \"۔\"\n",
    "    \"\"\"\n",
    "    matches = [m.end() for m in re.finditer(r'(?i)Story:', text)]\n",
    "    if matches:\n",
    "        extracted_text = text[matches[-1]:].strip()\n",
    "        # Using the correct Urdu full stop\n",
    "        last_full_stop = extracted_text.rfind(\"۔\")\n",
    "        if last_full_stop != -1:\n",
    "            return extracted_text[:last_full_stop + 1].strip()\n",
    "    return \"\"\n",
    "\n",
    "def remove_duplicate_sentences(text: str) -> str:\n",
    "    \"\"\"Removes duplicate sentences from the text based on the Urdu full stop '۔'.\"\"\"\n",
    "    # Using the correct Urdu full stop\n",
    "    sentences = text.split(\"۔\")\n",
    "    seen = set()\n",
    "    cleaned_sentences = []\n",
    "    for sentence in sentences:\n",
    "        sentence = sentence.strip()\n",
    "        if sentence and sentence not in seen:\n",
    "            seen.add(sentence)\n",
    "            cleaned_sentences.append(sentence)\n",
    "    # Using the correct Urdu full stop for joining\n",
    "    return \"۔ \".join(cleaned_sentences) + \"۔\" if cleaned_sentences else \"\"\n",
    "\n",
    "# ----------------------------\n",
    "# Story Generation Function\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "def generate_story_outline(concept: str, initial_story: str = \"\", max_steps: int = 9) -> str:\n",
    "    \"\"\"\n",
    "    Generates a structured, coherent, and grammatically sound Urdu story iteratively.\n",
    "    Uses a step-wise template to build narrative depth, with explicit instructions to ensure\n",
    "    a complete and engaging journey that concludes definitively.\n",
    "    \"\"\"\n",
    "    if model is None or tokenizer is None or device is None:\n",
    "        return \"Model or tokenizer not loaded. Cannot generate story. Please check your environment setup and model paths/permissions.\"\n",
    "\n",
    "    story_text = initial_story\n",
    "    complete_story = initial_story\n",
    "\n",
    "    for step in range(1, max_steps + 1):\n",
    "        if step == 1:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "[🔹 آغاز کریں:\n",
    "- جملے چھوٹے اور براہ راست ہوں۔\n",
    "- کہانی میں اسرار اور دلچسپی پیدا کریں۔\n",
    "- صرف اردو میں کہانی شروع کریں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کا دلکش آغاز کریں۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 2:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 کہانی کو آگے بڑھائیں:\n",
    "- کردار کے ابتدائی ارادوں اور چھپے رازوں کو نمایاں کریں۔\n",
    "- کہانی میں مزید سوالات اور اسرار پیدا کریں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کو ایک نیا موڑ دیں اور گہرائی پیدا کریں۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 3:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 تناؤ اور کشمکش کو بڑھائیں:\n",
    "- کردار کی داخلی کشمکش اور غیر متوقع موڑ کو اجاگر کریں۔\n",
    "- کہانی میں پیچیدگی اور دلچسپی پیدا کریں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کو ایک ایسے مقام پر لے جائیں جہاں قاری حیران رہ جائے۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 4:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 عروج کی طرف بڑھیں:\n",
    "- کہانی میں سنسنی خیزی اور نئے انکشافات شامل کریں۔\n",
    "- کرداروں کی جدوجہد اور مقابلے کو واضح کریں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کو ایک عروج پر پہنچائیں جہاں ہر لمحہ نیا انکشاف ہو۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 5:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 موڑ اور نیا رخ:\n",
    "- کہانی کو ایک نئے اور غیر متوقع موڑ پر لے جائیں۔\n",
    "- مزاحمت اور چیلنجز کو اجاگر کریں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی میں نیا رخ اور مزید کشمکش شامل کریں۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 6:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 اختتامی مراحل کی طرف بڑھیں:\n",
    "- کہانی کو مزید تفصیل سے بیان کریں اور چیلنجز کی شدت بڑھائیں۔\n",
    "- کردار کی جدوجہد کو گہرائی سے پیش کریں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کو اختتامی مراحل کی طرف لے جائیں، مگر ایک آخری حیران کن موڑ چھوڑیں۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 7:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 مکمل اختتام کی تیاری:\n",
    "- کہانی کو ایک مربوط اور مکمل انجام کی طرف لے جائیں۔\n",
    "- تمام اہم موڑ اور کشمکش کو حل کریں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کو شاندار انجام تک پہنچائیں۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 8:\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 جزئیات کی ترتیب اور اختتام:\n",
    "- کہانی کو مکمل کریں اور آخری تاثرات چھوڑیں۔\n",
    "- غیر ضروری تفصیلات کو حذف کرتے ہوئے مرکزی کہانی پر توجہ دیں۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کو ایک واضح اور مکمل انجام کے ساتھ ختم کریں۔**\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "        elif step == 9:  # Final polishing step with lower temperature for coherence\n",
    "            template = f\"\"\"\n",
    "**💡 بنیادی خیال:** {concept}\n",
    "\n",
    "کہانی:\n",
    "{story_text}\n",
    "\n",
    "[🔹 براہ کرم کہانی کو ایک مکمل، مربوط اور دلکش انجام تک پہنچائیں:\n",
    "- کہانی کے تمام اہم موڑ اور کشمکش کو حل کریں۔\n",
    "- کردار کی ذہنی اور جذباتی ترقی کو اجاگر کریں۔\n",
    "- روزمرہ کی تفصیلات سے ہٹ کر ایک دلچسپ سفر اور تبدیلی کو مرکزی حیثیت دیں۔\n",
    "- کہانی ایک واضح، اثر انگیز اختتام پر ختم ہو۔]\n",
    "\n",
    "📜 **براہ کرم کہانی کو مکمل اور مربوط اختتام کے ساتھ ختم کریں۔**\n",
    "صرف اردو میں کہانی لکھیں اور اضافی ہدایات شامل نہ کریں۔\n",
    "After this dont write indicators for users just Start the story in Urdu only after the word \"Story:\"\n",
    "            \"\"\"\n",
    "\n",
    "        # Prepare input tokens from the template\n",
    "        inputs = tokenizer(template, return_tensors=\"pt\").to(device)\n",
    "\n",
    "        # Adjust max tokens and temperature per step\n",
    "        max_tokens = 250\n",
    "        temperature = 0.7\n",
    "        if step >= 7:\n",
    "            max_tokens = 400\n",
    "        if step == 9:\n",
    "            max_tokens = 500\n",
    "            temperature = 0.6\n",
    "\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_tokens,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_p=0.9,\n",
    "            top_k=50,\n",
    "            repetition_penalty=1.1,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            early_stopping=True,\n",
    "            return_dict_in_generate=True\n",
    "        )\n",
    "\n",
    "        # Extract the new text generated after the last occurrence of \"Story:\"\n",
    "        new_text = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "        extracted_text = extract_text_after_last_story(new_text)\n",
    "\n",
    "        # Update story text for the next step\n",
    "        story_text = extracted_text\n",
    "        complete_story += \" \" + extracted_text\n",
    "\n",
    "    complete_story = remove_duplicate_sentences(complete_story)\n",
    "    return complete_story\n",
    "\n",
    "app = FastAPI()\n",
    "\n",
    "class StoryRequest(BaseModel):\n",
    "    concept: str\n",
    "    initial_story: str = \"\"\n",
    "    max_steps: int = 9\n",
    "\n",
    "@app.post(\"/generate_story/\")\n",
    "async def generate_story(request: StoryRequest):\n",
    "    try:\n",
    "        story = generate_story_outline(request.concept, request.initial_story, request.max_steps)\n",
    "        return {\"story\": story}\n",
    "    except Exception as e:\n",
    "        # Log the exception for debugging\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise HTTPException(status_code=500, detail=f\"An error occurred during story generation: {e}\")\n",
    "\n",
    "# Code to run the FastAPI app with uvicorn and expose with ngrok\n",
    "# This pattern is suitable for environments like Google Colab or Jupyter notebooks\n",
    "if __name__ == \"__main__\":\n",
    "    # Set the ngrok authtoken from environment variable\n",
    "    # Make sure to set the NGROK_AUTH_TOKEN environment variable\n",
    "    ngrok_auth_token = os.environ.get(\"NGROK_AUTH_TOKEN\")\n",
    "    if ngrok_auth_token:\n",
    "        ngrok.set_auth_token(ngrok_auth_token)\n",
    "    else:\n",
    "        print(\"Warning: NGROK_AUTH_TOKEN environment variable not set. ngrok might not work.\")\n",
    "\n",
    "\n",
    "    # Define the port for FastAPI\n",
    "    port = 8000\n",
    "\n",
    "    # Start ngrok tunnel\n",
    "    try:\n",
    "        print(f\"Starting ngrok tunnel for port {port}...\")\n",
    "        # Use bind_tls=True if you need HTTPS, but stick to False for simplicity if not required\n",
    "        public_url = ngrok.connect(port, \"http\", bind_tls=False).public_url\n",
    "        print(f\" FastAPI app is exposed at: {public_url}\")\n",
    "        print(f\"Access the FastAPI docs at: {public_url}/docs\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error starting ngrok tunnel: {e}\")\n",
    "        print(\"Please ensure ngrok is installed, authenticated, and not already running on this port.\")\n",
    "        public_url = None # Set to None if ngrok fails\n",
    "\n",
    "    # Run the FastAPI application using uvicorn in a separate thread\n",
    "    # Only start the thread if ngrok started successfully or if you intend to access locally\n",
    "    if public_url or not ngrok_auth_token: # Added condition to allow local run without ngrok token\n",
    "        try:\n",
    "            print(\"Starting Uvicorn server in a separate thread...\")\n",
    "            # Use reload=False when running with ngrok to avoid issues\n",
    "            # daemon=True allows the thread to exit when the main program exits\n",
    "            uvicorn_thread = Thread(target=uvicorn.run,\n",
    "                                    kwargs={\"app\": app, \"host\": \"0.0.0.0\", \"port\": port, \"reload\": False},\n",
    "                                    daemon=True)\n",
    "            uvicorn_thread.start()\n",
    "            print(\"Uvicorn server thread started. The script can now continue.\")\n",
    "            # If running as a script, you might want to add a line here to keep the main thread alive,\n",
    "            # e.g., input(\"Press Enter to stop the server...\\n\") or a loop\n",
    "            # In Colab, the notebook environment keeps the script alive.\n",
    "        except Exception as e:\n",
    "            print(f\"Error starting uvicorn thread: {e}\")\n",
    "            print(\"Please check if the port is already in use.\")\n",
    "    else:\n",
    "        print(\"ngrok failed to start. Uvicorn server will not be started automatically.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
